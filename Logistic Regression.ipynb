{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Logistic Regression to predict whether the song will be a hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #to split data into test/train \n",
    "from patsy import dmatrices #to split data into matrices for model \n",
    "from sklearn.linear_model import LogisticRegression #to fit a logistic regression classifier\n",
    "from sklearn import metrics #to compute accuracy score \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #to ignore warnings\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('No_Outliers_Spotify.csv') #importing data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes the data set, the formula of independent variables predicting the dependent, and the specified target variable. It splits the data into train (70%) and test (30%). Then, it fits a logistic regression to the training data and computes the train and test accuracy scores. Finally, it compares these scores to the baseline model score. The baseline model is a model that simply predicts the outcome that is most common in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df,formula,y_var):\n",
    "    Y, X = dmatrices(formula, df, return_type='dataframe') #transform data into matrices\n",
    "    y = Y[y_var].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) #split into test and train\n",
    "    model = LogisticRegression() #fit logistic regression model \n",
    "    result = model.fit(X_train, y_train)\n",
    "    prediction_train = model.predict(X_train) #predict model with training data \n",
    "    print(\"Train Accuracy: \",metrics.accuracy_score(y_train, prediction_train)) #compare actual vs predicted scores for train\n",
    "    prediction = model.predict(X_test) #predict model with test data\n",
    "    print(\"Test Accuracy: \",metrics.accuracy_score(y_test, prediction)) #compare actual vs predicted scores for test\n",
    "    #comparing to baseline\n",
    "    num_pos = len(y_train[y_train==1])\n",
    "    num_neg = len(y_train[y_train==0])\n",
    "    #want max value as that's what baseline would choose:\n",
    "    if num_pos >= num_neg: #if most common outcome is a 1\n",
    "        max_val = 1\n",
    "    else: #if most common outcome is a 0\n",
    "        max_val = 0\n",
    "    #compute accuracy for baseline model \n",
    "    correct_examples_in_test = len(y_test[y_test==max_val]) \n",
    "    total_examples_in_test = len(y_test)\n",
    "    print('Number of examples where baseline is correct =', correct_examples_in_test)\n",
    "    print('Baseline accuracy =', correct_examples_in_test * 1.0 / total_examples_in_test)\n",
    "    print(\"Variables weights:\",model.coef_)\n",
    "    print(\"Intercept:\",model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I apply the function to our data using the independent variables selected by stepwise regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8087357569180683\n",
      "Test Accuracy:  0.829746835443038\n",
      "Number of examples where baseline is correct = 818\n",
      "Baseline accuracy = 0.5177215189873418\n",
      "Variables weights: [[-0.28406032  0.27791191 -4.94196468  4.69901682  0.41089726 -5.15041623\n",
      "  -1.38164077  0.54518021]]\n",
      "Intercept: [2.22234958]\n"
     ]
    }
   ],
   "source": [
    "predictors = 'target ~ 0 + instrumentalness + danceability + loudness + energy + acousticness + C(mode) + time_signature'\n",
    "train_test(df,predictors,'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our logistic regression model performed with 80.8% train accuracy, 82.97% test accuracy, and had a baseline accuracy of 51.7%. Clearly the logistic regression model outperforms the baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model__\n",
    "\n",
    "Target = 2.22 + 0.278(instrumentalness) - 4.941(danceability) + 4.699(loudness) + 0.411(energy) -  5.150(acousticness) - 1.381(mode) + 0.545(time_signature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
